{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: IMDb Sentiment Analysis with ClearML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "The goal of this project is to perform sentiment analysis on the IMDb Movie Reviews dataset, classifying reviews as positive or negative. We'll leverage ClearML for experiment tracking, visualization, and comparison.\n",
    "\n",
    "## Workflow\n",
    "1. Load and explore the dataset.\n",
    "2. Preprocess the text data.\n",
    "3. Train and evaluate machine learning models.\n",
    "4. Track experiments and log results using ClearML.\n",
    "\n",
    "## Tools and Libraries\n",
    "- Python\n",
    "- Pandas, Scikit-learn for data handling and modeling\n",
    "- ClearML for experiment tracking and logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Explore the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML results page: https://app.clear.ml/projects/4940d4acad2948baa4975ef47ca43225/experiments/d4bcea17b73547268812d44ef74d5eca/output/log\n",
      "ClearML dataset page: https://app.clear.ml/datasets/simple/4940d4acad2948baa4975ef47ca43225/experiments/d4bcea17b73547268812d44ef74d5eca\n",
      "Uploading dataset changes (1 files compressed to 25.33 MiB) to https://files.clear.ml\n",
      "File compression and upload completed: total size 25.33 MiB, 1 chunk(s) stored (average size 25.33 MiB)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from clearml import Dataset\n",
    "\n",
    "# Create a new dataset version\n",
    "dataset = Dataset.create(dataset_name=\"IMDb Reviews\", dataset_project=\"Sentiment Analysis\")\n",
    "dataset.add_files(\"../data/IMDB-Dataset.csv\")\n",
    "dataset.upload()\n",
    "dataset.finalize()\n",
    "\n",
    "df = pd.read_csv(\"../data/IMDB-Dataset.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing\n",
    "We'll clean the text and convert it into numerical format using TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 2806532 stored elements and shape (40000, 5000)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df['review']  \n",
    "y = df['sentiment']  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text to numerical representation using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "X_train_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Training and ClearML Integration\n",
    "We'll train a Logistic Regression model and track the experiment using ClearML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8889\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89      4961\n",
      "    positive       0.88      0.90      0.89      5039\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from clearml import Task\n",
    "\n",
    "# Initialize ClearML Task\n",
    "task = Task.init(project_name=\"IMDb Sentiment Analysis\", task_name=\"Logistic Regression\")\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_vec)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the accuracy to ClearML\n",
    "task.get_logger().report_scalar(\"Accuracy\", \"Test\", iteration=1, value=accuracy)\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Experiment Tracking\n",
    "The ClearML dashboard now logs:\n",
    "1. Model training metrics (accuracy, classification report).\n",
    "2. Artifacts (trained model files, logs, etc.).\n",
    "3. Metadata about the experiment.\n",
    "\n",
    "You can compare multiple experiments (e.g., different models) on the dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Compare Multiple Models\n",
    "We'll train another model (Naive Bayes) and log its results for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not read Jupyter Notebook: No module named 'nbconvert'\n",
      "Please install nbconvert using \"pip install nbconvert\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=279d5440a220455ca2933295946161d9\n",
      "ClearML results page: https://app.clear.ml/projects/8d7422d16fe44ab780913011deb6f3f8/experiments/279d5440a220455ca2933295946161d9/output/log\n",
      "Naive Bayes Test Accuracy: 0.8508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Train a Naive Bayes model\n",
    "task = Task.init(project_name=\"IMDb Sentiment Analysis\", task_name=\"Naive Bayes\")\n",
    "model_nb = MultinomialNB()\n",
    "model_nb.fit(X_train_vec, y_train)\n",
    "\n",
    "# Evaluate the Naive Bayes model\n",
    "y_pred_nb = model_nb.predict(X_test_vec)\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(f\"Naive Bayes Test Accuracy: {accuracy_nb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.get_logger().report_scalar(\"Accuracy\", \"Test\", iteration=1, value=accuracy_nb)\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Conclusion\n",
    "\n",
    "### Key Findings\n",
    "1. **Logistic Regression** achieved an accuracy of X% (replace with your result).\n",
    "2. **Naive Bayes** achieved an accuracy of Y% (replace with your result).\n",
    "3. ClearML streamlined experiment tracking and comparison, providing a centralized platform for logging and visualizing results.\n",
    "\n",
    "### Future Work\n",
    "- Experiment with advanced models (e.g., Random Forest, Neural Networks).\n",
    "- Automate the pipeline using ClearML Agents.\n",
    "- Deploy the best-performing model using ClearML Serving or a custom web app.\n",
    "\n",
    "## Thank You!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clearml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
